% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Individual Tree Detection},
  pdfauthor={Sam Ericksen, Oren Nardi},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{Individual Tree Detection}
\author{Sam Ericksen, Oren Nardi}
\date{2022-03-15}

\begin{document}
\maketitle

data collected by Oren Nardi, at College of the Redwoods campus in
Eureka.

Images processed in WebODM using the defualt ``Forest'' parameters

\hypertarget{reading-a-point-cloud}{%
\subsection{Reading a Point Cloud}\label{reading-a-point-cloud}}

First, using the LidR package, we read in the dataset in question. In
this case, to make the script more universally available for all users
we use the choose.file() function. This function opens a file explorer
box that allows the user to choose any file from there computer as they
wish. We also want to do a quick initial validity test on the data -
simply ploting it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{las }\OtherTok{\textless{}{-}} \FunctionTok{readLAS}\NormalTok{(}\FunctionTok{file.choose}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Invalid data: RGB colors are recorded on 8 bits instead of 16 bits.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\# }
\DocumentationTok{\#\# plot(las) \#\# initiates a 3D plot, must be run in R}
\DocumentationTok{\#\# }
\end{Highlighting}
\end{Shaded}

We can also run a deep check on the las to see if any issues are present
that may impede future analysis using las\_check(). It's also nice to
check and see if the file is already normalized visually, this can be
done by plotting the minimum height values.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{las\_check}\NormalTok{(las)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Checking the data
##   - Checking coordinates...[0;32m <U+2713>[0m
##   - Checking coordinates type...[0;32m <U+2713>[0m
##   - Checking coordinates range...[0;32m <U+2713>[0m
##   - Checking coordinates quantization...[0;32m <U+2713>[0m
##   - Checking attributes type...[0;32m <U+2713>[0m
##   - Checking ReturnNumber validity...[0;32m <U+2713>[0m
##   - Checking NumberOfReturns validity...[0;32m <U+2713>[0m
##   - Checking ReturnNumber vs. NumberOfReturns...[0;32m <U+2713>[0m
##   - Checking RGB validity...
##  [1;33m   <U+26A0> Invalid data: RGB colors are recorded on 8 bits instead of 16 bits.[0m
##   - Checking absence of NAs...[0;32m <U+2713>[0m
##   - Checking duplicated points...
##  [1;33m   <U+26A0> 36 points are duplicated and share XYZ coordinates with other points[0m
##   - Checking degenerated ground points...[0;37m skipped[0m
##   - Checking attribute population...
##  [0;32m   <U+0001F6C8> 'gpstime' attribute is not populated[0m
##  [0;32m   <U+0001F6C8> 'PointSourceID' attribute is not populated[0m
##  [0;32m   <U+0001F6C8> 'ScanDirectionFlag' attribute is not populated[0m
##  [0;32m   <U+0001F6C8> 'EdgeOfFlightline' attribute is not populated[0m
##   - Checking gpstime incoherances
##  [0;31m   <U+2717> 1 pulses (points with the same gpstime) have points with identical ReturnNumber[0m
##   - Checking flag attributes...[0;32m <U+2713>[0m
##   - Checking user data attribute...
##  [0;32m   <U+0001F6C8> 1111572 points have a non 0 UserData attribute. This probably has a meaning[0m
##  Checking the header
##   - Checking header completeness...[0;32m <U+2713>[0m
##   - Checking scale factor validity...[0;32m <U+2713>[0m
##   - Checking point data format ID validity...[0;32m <U+2713>[0m
##   - Checking extra bytes attributes validity...[0;32m <U+2713>[0m
##   - Checking the bounding box validity...[0;32m <U+2713>[0m
##   - Checking coordinate reference system...[0;32m <U+2713>[0m
##  Checking header vs data adequacy
##   - Checking attributes vs. point format...[0;32m <U+2713>[0m
##   - Checking header bbox vs. actual content...[0;32m <U+2713>[0m
##   - Checking header number of points vs. actual content...[0;32m <U+2713>[0m
##   - Checking header return number vs. actual content...[0;32m <U+2713>[0m
##  Checking coordinate reference system...
##   - Checking if the CRS was understood by R...[0;32m <U+2713>[0m
##  Checking preprocessing already done 
##   - Checking ground classification...[0;31m no[0m
##   - Checking normalization...[0;31m no[0m
##   - Checking negative outliers...[0;32m <U+2713>[0m
##   - Checking flightline classification...[0;31m no[0m
##  Checking compression
##   - Checking attribute compression...
##  [0;32m   <U+0001F6C8> Compression supported only from rlas 1.6.0[0m
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{epsg}\NormalTok{(las) }\DocumentationTok{\#\#get the coordinate system of the file.  Here we get 32610, which has a vertical unit of meters, so we know the Z values will be in meters}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 32610
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{pixel\_metrics}\NormalTok{(las, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{min}\NormalTok{(Z), }\AttributeTok{res =} \DecValTok{10}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\includegraphics{IDT_cor_files/figure-latex/check pointcloud-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{min}\NormalTok{(las}\SpecialCharTok{@}\NormalTok{data}\SpecialCharTok{$}\NormalTok{Z)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 15.97
\end{verbatim}

Here both las\_check() and a plot of minimum height values indicate a
non-normalized point cloud (all values are above 0 meters).
Additionally, the deep check of the file indicates a few interesting
anomolies that need to be addressed:

\begin{itemize}
\tightlist
\item
  There are a few duplicate points that should be filtered out
\item
  Ground points are not classified
\item
  There is some issue with the RGB data, but this is likely only an
  issue for LidR, and can be ignored for now
\end{itemize}

Duplicates can be filtered very quickly:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{las }\OtherTok{\textless{}{-}} \FunctionTok{filter\_duplicates}\NormalTok{(las)}
\end{Highlighting}
\end{Shaded}

\hypertarget{classifying-ground-points}{%
\subsection{Classifying Ground Points}\label{classifying-ground-points}}

When working with point clouds derived from photogrammetry, there is
often no classifications initially associated with the points. ASPRS
provides a
\href{chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/viewer.html?pdfurl=https\%3A\%2F\%2Fwww.asprs.org\%2Fwp-content\%2Fuploads\%2F2010\%2F12\%2FLAS_Specification.pdf\&clen=3783348\&chunk=true}{structure
for classification of point clouds} to work with, but for now our main
concern are ground points. Without ground points classified it is not
possible to create a canopy height model, as the canopy height is
derived in relation to the ground surface.

When we plotted the point cloud earlier we noticed that there aren't
many points under the canopy, this makes ground classification a little
tricky. Fortunately, there were ground points collected on the outskirts
of the area of interest, so we can work with that.

Because of the lack of ground under the canopy we will use a Cloth
Simulation Filter (Zhang et al. 2016). There are a few attributes that
can be adjusted by the user, and the most important in this case is
cloth rigidness, although 3L is generally for flat ground, to force some
interpretation of the under-canopy ground we will use this setting. Once
ground points are classified we plot just the ground points (ASPRS class
2L) to see how it performed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{las }\OtherTok{\textless{}{-}} \FunctionTok{classify\_ground}\NormalTok{(las, }\FunctionTok{csf}\NormalTok{(}\AttributeTok{rigidness =}\NormalTok{ 2L))}

\DocumentationTok{\#\# plot(pixel\_metrics(las[las@data$Classification==2L], \textasciitilde{}mean(Z), res = 2))}
\DocumentationTok{\#\# }
\DocumentationTok{\#\# plot(las[las@data$Classification==2L])}
\end{Highlighting}
\end{Shaded}

Plotting the average height value of the ground points shows that there
are clearly some miss-classified ground points back where the canopy is
very dense (Northeast corner). It looks like we can safely remove ground
points above 40m during creation of a canopy height model.

\hypertarget{creating-a-canopy-height-model}{%
\subsection{Creating a Canopy Height
Model}\label{creating-a-canopy-height-model}}

The first step in creating a canopy height model will be the creation of
a digital terrain model (DTM). There are a three methods of this
included in the LidR package:

\begin{itemize}
\item
  K-Nearest Neighbor Methods

  \begin{itemize}
  \item
    Inverse Distance Weighting
  \item
    Krigging
  \end{itemize}
\item
  Delaunay Triagulation
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grnd\_points }\OtherTok{\textless{}{-}} \FunctionTok{filter\_poi}\NormalTok{(las, Classification }\SpecialCharTok{==}\NormalTok{ 2L, Z }\SpecialCharTok{\textless{}} \DecValTok{40}\NormalTok{) }\DocumentationTok{\#\#filter point cloud to include only non{-}anomalous ground points}

\NormalTok{idw\_terrain }\OtherTok{\textless{}{-}} \FunctionTok{rasterize\_terrain}\NormalTok{(grnd\_points, }\AttributeTok{algorithm =} \FunctionTok{knnidw}\NormalTok{())}
\NormalTok{krig\_terrain }\OtherTok{\textless{}{-}} \FunctionTok{rasterize\_terrain}\NormalTok{(grnd\_points, }\AttributeTok{algorithm =} \FunctionTok{kriging}\NormalTok{())}
\NormalTok{tin\_terrain }\OtherTok{\textless{}{-}} \FunctionTok{rasterize\_terrain}\NormalTok{(grnd\_points, }\AttributeTok{algorithm =} \FunctionTok{tin}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\includegraphics{IDT_cor_files/figure-latex/DTM creation-1.pdf}
\includegraphics{IDT_cor_files/figure-latex/DTM creation-2.pdf}
\includegraphics{IDT_cor_files/figure-latex/DTM creation-3.pdf}

Here we can see the Kriging does not deal with extrapolation well with
default parameters. IDW and TINing seem to give reasonable outputs and a
closer inspection seems to indicate that TINing gave a smother slope
transition when extrapolating under-canopy ground points. We will
continue with the canopy height model using the DTM created using
TINing, but one couldn't be blamed for considering using the IDW terrain
model either.

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-zhang2016}{}}%
Zhang, Wuming, Jianbo Qi, Peng Wan, Hongtao Wang, Donghui Xie, Xiaoyan
Wang, and Guangjian Yan. 2016. {``An Easy-to-Use Airborne LiDAR Data
Filtering Method Based on Cloth Simulation.''} \emph{Remote Sensing} 8
(6): 501. \url{https://doi.org/10.3390/rs8060501}.

\end{CSLReferences}

\end{document}
